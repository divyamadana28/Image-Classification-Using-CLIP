Zero-Shot Learning (ZSL) is a problem setup in a Machine Learning, where at testing, a learner observes samples from classes that were not observed while training the 
model and predicts the category they belong to. Zero-Shot Learning is attracting more and more research interest in recent years . Side Information is an important key 
to ZSL , since it transfers the knowledge between seen and unseen classes. The most popular side information i.e., Human annotated attributes needs much human efforts 
and time consumption during data collection. While Unsupervised side information such as vectors of word labels is not performing well , since they lack the 
representation ability for visual information. So, we propose to use Contrastive Language Image Pre-training(CLIP) features,which is learned with image and natural 
language pairs without human efforts, to perform ZSL for achieving impressive accuracy.

